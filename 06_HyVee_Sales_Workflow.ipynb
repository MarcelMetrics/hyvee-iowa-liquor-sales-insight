{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import datetime\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_filenames = [\n",
    "    # Execute ETL_Env_Setup only in initial attempt\n",
    "    '02_HyVee_Sales_ETL_Env_Setup.py',\n",
    "    '03_HyVee_Sales_ETL_Pipeline.py',\n",
    "    '04_HyVee_Sales_Data_Modeling.py',\n",
    "    '05_HyVee_Sales_Feature_Engineering.py'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store log data\n",
    "log_data = []\n",
    "execution_date = date.today()\n",
    "process_start_time = datetime.datetime.now()\n",
    "\n",
    "for filename in script_filenames:\n",
    "    try:\n",
    "        subprocess.run(['python', filename], check=True)\n",
    "        success = True\n",
    "    except subprocess.CalledProcessError:\n",
    "        success = False\n",
    "\n",
    "process_end_time = datetime.datetime.now()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00:01:27.910'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_process_duration = (process_end_time - process_start_time).total_seconds()\n",
    "\n",
    "def format_duration(duration_seconds):\n",
    "    hours, remainder = divmod(duration_seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    # Format as \"HH:MM:SS.sss\"\n",
    "    return f\"{int(hours):02d}:{int(minutes):02d}:{seconds:06.3f}\"\n",
    "\n",
    "total_process_duration = format_duration(total_process_duration)\n",
    "total_process_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch data-related info from database\n",
    "with open('config\\mysql_config.json') as f:\n",
    "  mysql_config = json.load(f)\n",
    "\n",
    "db_config = {\n",
    "    'host': mysql_config['hostname'],\n",
    "    'user': mysql_config['username'],\n",
    "    'password': mysql_config['password'],\n",
    "    'db': 'STG_HYVEE'\n",
    "}\n",
    "\n",
    "def get_db_connection():\n",
    "    return pymysql.connect(**db_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_record_count():\n",
    "    conn = get_db_connection()\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            sql = \"SELECT COUNT(*) FROM sales\"\n",
    "            cursor.execute(sql)\n",
    "            (count,) = cursor.fetchone()\n",
    "            return count\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "record_count = fetch_record_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data_date_range():\n",
    "    conn = get_db_connection()\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            sql = \"SELECT MIN(date), MAX(date) FROM sales\"\n",
    "            cursor.execute(sql)\n",
    "            start_date, end_date = cursor.fetchone()\n",
    "            return start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "data_start_date, data_end_date = fetch_data_date_range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate New Records Added\n",
    "csv_filename = 'execution_log_summary.csv'\n",
    "\n",
    "if os.path.exists(csv_filename):\n",
    "    # If the CSV exists, read it to get the last execution's record count\n",
    "    df_previous_logs = pd.read_csv(csv_filename)\n",
    "    \n",
    "    if not df_previous_logs.empty:\n",
    "        last_execution_record_count = df_previous_logs.iloc[-1]['Record Count']\n",
    "        new_records_added = record_count - last_execution_record_count\n",
    "    else:\n",
    "        # If the CSV exists but is empty (unlikely, but to be safe)\n",
    "        new_records_added = 0\n",
    "else:\n",
    "    # If the CSV does not exist, this is the initial execution\n",
    "    new_records_added = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Execution Date   Process Start Time     Process End Time Total Duration  \\\n",
      "0     2024-02-22  2024-02-22 22:34:18  2024-02-22 22:35:46   00:01:27.910   \n",
      "\n",
      "  Data Start Date Data End Date  Record Count  New Records Added  \n",
      "0      2023-07-03    2024-01-31        418808              31645  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Execution Date      1 non-null      object\n",
      " 1   Process Start Time  1 non-null      object\n",
      " 2   Process End Time    1 non-null      object\n",
      " 3   Total Duration      1 non-null      object\n",
      " 4   Data Start Date     1 non-null      object\n",
      " 5   Data End Date       1 non-null      object\n",
      " 6   Record Count        1 non-null      int64 \n",
      " 7   New Records Added   1 non-null      int64 \n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 196.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# Add overall process metrics to the log\n",
    "log_data.append({\n",
    "    'Execution Date': execution_date,\n",
    "    'Process Start Time': process_start_time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'Process End Time': process_end_time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'Total Duration': total_process_duration,\n",
    "    'Data Start Date': data_start_date,\n",
    "    'Data End Date': data_end_date,\n",
    "    'Record Count': record_count,\n",
    "    'New Records Added': new_records_added\n",
    "})\n",
    "\n",
    "# Create a DataFrame from the log data\n",
    "df_logs = pd.DataFrame(log_data)\n",
    "\n",
    "# Display or save the log DataFrame\n",
    "print(df_logs)\n",
    "\n",
    "df_logs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the CSV file already exists to determine if the header should be written\n",
    "csv_file_exists = os.path.isfile(csv_filename)\n",
    "\n",
    "# Append the log DataFrame to the CSV file, write header only if the file doesn't exist\n",
    "df_logs.to_csv(csv_filename, mode='a', header=not csv_file_exists, index=False)\n",
    "\n",
    "# Read the updated CSV to ensure it includes all appended data\n",
    "df_logs_updated = pd.read_csv(csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the updated DataFrame to Markdown\n",
    "def df_to_md(df):\n",
    "    # Add the header row\n",
    "    markdown_table = \"| \" + \" | \".join(df.columns) + \" |\\n\"\n",
    "    \n",
    "    # Add the separator row\n",
    "    markdown_table += \"| \" + \" | \".join([\"---\"] * len(df.columns)) + \" |\\n\"\n",
    "    \n",
    "    # Add data rows\n",
    "    for index, row in df.iterrows():\n",
    "        markdown_str = \"| \" + \" | \".join(str(value) for value in row) + \" |\"\n",
    "        markdown_table += markdown_str + \"\\n\"\n",
    "    \n",
    "    return markdown_table\n",
    "\n",
    "markdown_table = df_to_md(df_logs_updated)\n",
    "\n",
    "md_title = \"# Execution Log Summary\\n\\n\"\n",
    "\n",
    "markdown_content = md_title + markdown_table\n",
    "\n",
    "markdown_filename = 'execution_log_summary.md'\n",
    "\n",
    "with open(markdown_filename, 'w') as md_file:\n",
    "    md_file.write(markdown_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
